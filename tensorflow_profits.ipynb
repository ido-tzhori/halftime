{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "179d11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import kerastuner as kt\n",
    "from kerastuner import RandomSearch\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n",
    "from keras.callbacks import EarlyStopping\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b475d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kelly(p, b, weight):\n",
    "    stake = round((p * (b - 1) - (1 - p)) / (b - 1), 4) * weight\n",
    "    return stake if stake > 0.0 else 'no value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "4e699c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(358, 334)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('for_tf_df.csv', index_col = [0]).reset_index(drop = True)\n",
    "df = df[df['odds_sum'] > 1.02]\n",
    "df = df.dropna(axis = 1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "13c70b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,:-1], df.iloc[:, -1], test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "963216ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_n = tf.keras.utils.normalize(X_train, axis = 1)\n",
    "X_test_n = tf.keras.utils.normalize(X_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "48a7d667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    \"\"\"\n",
    "    Builds model and sets up hyperparameter space to search.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    hp : HyperParameter object\n",
    "        Configures hyperparameters to tune.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    model : keras model\n",
    "        Compiled model with hyperparameters to tune.\n",
    "    \"\"\"\n",
    "    # Initialize sequential API and start building model.\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten())\n",
    "    \n",
    "    # Tune the number of hidden layers and units in each.\n",
    "    # Number of hidden layers: 1 - 4\n",
    "    for i in range(1, hp.Int(\"num_layers\", 2, 6)):\n",
    "        model.add(\n",
    "            keras.layers.Dense(\n",
    "                units=hp.Int(\"units_\" + str(i), min_value=5, max_value=15, step=2),\n",
    "                activation=\"relu\")\n",
    "            )\n",
    "        \n",
    "        # Tune dropout layer with values from 0 - 0.3 with stepsize of 0.1.\n",
    "        model.add(keras.layers.Dropout(hp.Float(\"dropout_\" + str(i), 0, 0.3, step=0.1)))\n",
    "    \n",
    "    # Add output layer.\n",
    "    model.add(keras.layers.Dense(units=3, activation=\"softmax\"))\n",
    "    \n",
    "    # Tune learning rate for Adam optimizer with values from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    # Define optimizer, loss, and metrics\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "e661067a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project kt_dir\\kt_hyperband\\oracle.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective=\"val_accuracy\",\n",
    "                     executions_per_trial = 1,\n",
    "                     factor = 3,\n",
    "                     directory=\"kt_dir\",\n",
    "                     project_name=\"kt_hyperband\",)\n",
    "early_stopping = EarlyStopping(monitor=\"loss\", patience= 10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9d2dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(X_train_n, y_train, epochs=150, validation_data = (X_test_n, y_test), callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "4c86edf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0548 - accuracy: 0.3881\n",
      "Epoch 2/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.9743 - accuracy: 0.5784\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.9166 - accuracy: 0.6119\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8745 - accuracy: 0.6194\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.8455 - accuracy: 0.6194\n",
      "Epoch 6/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8261 - accuracy: 0.6343\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8094 - accuracy: 0.6493\n",
      "Epoch 8/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7984 - accuracy: 0.6567\n",
      "Epoch 9/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7815 - accuracy: 0.6530\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7723 - accuracy: 0.6679\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7622 - accuracy: 0.6716\n",
      "Epoch 12/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7530 - accuracy: 0.6866\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7446 - accuracy: 0.6716\n",
      "Epoch 14/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7343 - accuracy: 0.6791\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7436 - accuracy: 0.6791\n",
      "Epoch 16/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7309 - accuracy: 0.6828\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7142 - accuracy: 0.6940\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7156 - accuracy: 0.6940\n",
      "Epoch 19/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7001 - accuracy: 0.6754\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.6978\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.7164\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6876 - accuracy: 0.6903\n",
      "Epoch 23/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.7052\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6736 - accuracy: 0.7164\n",
      "Epoch 25/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.7090\n",
      "Epoch 26/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6696 - accuracy: 0.7052\n",
      "Epoch 27/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6527 - accuracy: 0.7164\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6475 - accuracy: 0.7052\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6413 - accuracy: 0.7127\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6472 - accuracy: 0.7015\n",
      "Epoch 31/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6526 - accuracy: 0.7239\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.7127\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6333 - accuracy: 0.7127\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.7313\n",
      "Epoch 35/150\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.7351\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6145 - accuracy: 0.7201\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.7425\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5992 - accuracy: 0.7425\n",
      "Epoch 39/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.7500\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.7388\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5779 - accuracy: 0.7463\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.7575\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.7687\n",
      "Epoch 44/150\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.5649 - accuracy: 0.7537\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.7425\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7649\n",
      "Epoch 47/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7799\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7799\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7836\n",
      "Epoch 50/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7799\n",
      "Epoch 51/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7948\n",
      "Epoch 52/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.7724\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7836\n",
      "Epoch 54/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7873\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5115 - accuracy: 0.8022\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7910\n",
      "Epoch 57/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.7985\n",
      "Epoch 58/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7873\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.8134\n",
      "Epoch 60/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.8022\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.8134\n",
      "Epoch 62/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7985\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.8097\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.8209\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.8097\n",
      "Epoch 66/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.8358\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4602 - accuracy: 0.8097\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.8321\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.8246\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4497 - accuracy: 0.8321\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.8321\n",
      "Epoch 72/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.8321\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8321\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8433\n",
      "Epoch 75/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8470\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4224 - accuracy: 0.8470\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4204 - accuracy: 0.8396\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4260 - accuracy: 0.8396\n",
      "Epoch 79/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4181 - accuracy: 0.8470\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8433\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 0.8321\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4129 - accuracy: 0.8433\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8507\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8545\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.4003 - accuracy: 0.8507\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8545\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8433\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3889 - accuracy: 0.8545\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8507\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8545\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3819 - accuracy: 0.8507\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3779 - accuracy: 0.8545\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8619\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3697 - accuracy: 0.8545\n",
      "Epoch 95/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8507\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3688 - accuracy: 0.8582\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3628 - accuracy: 0.8582\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8694\n",
      "Epoch 99/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3616 - accuracy: 0.8545\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3554 - accuracy: 0.8657\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3559 - accuracy: 0.8619\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3639 - accuracy: 0.8619\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3598 - accuracy: 0.8582\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3542 - accuracy: 0.8731\n",
      "Epoch 105/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8657\n",
      "Epoch 106/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3552 - accuracy: 0.8657\n",
      "Epoch 107/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3551 - accuracy: 0.8545\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3392 - accuracy: 0.8694\n",
      "Epoch 109/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3478 - accuracy: 0.8619\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3373 - accuracy: 0.8657\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8694\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8806\n",
      "Epoch 113/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8619\n",
      "Epoch 114/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3454 - accuracy: 0.8843\n",
      "Epoch 115/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3509 - accuracy: 0.8545\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8881\n",
      "Epoch 117/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8769\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8806\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8881\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8806\n",
      "Epoch 121/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8918\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8769\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8881\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8955\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8731\n",
      "Epoch 126/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.9030\n",
      "Epoch 127/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3076 - accuracy: 0.8806\n",
      "Epoch 128/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3102 - accuracy: 0.8955\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3149 - accuracy: 0.8657\n",
      "Epoch 130/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8881\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8657\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3254 - accuracy: 0.8731\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8955\n",
      "Epoch 134/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3233 - accuracy: 0.8619\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8806\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2866 - accuracy: 0.8881\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2867 - accuracy: 0.9030\n",
      "Epoch 138/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.8843\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2837 - accuracy: 0.9067\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2829 - accuracy: 0.8843\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2810 - accuracy: 0.9104\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2833 - accuracy: 0.8993\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2773 - accuracy: 0.9030\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2770 - accuracy: 0.9030\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2928 - accuracy: 0.8843\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2825 - accuracy: 0.8881\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2688 - accuracy: 0.9142\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2739 - accuracy: 0.8993\n",
      "Epoch 149/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2673 - accuracy: 0.9216\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.2692 - accuracy: 0.8881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f9fb156d08>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps=tuner.get_best_hyperparameters()[0]\n",
    "h_model = tuner.hypermodel.build(best_hps)\n",
    "h_model.fit(X_train_n, y_train, epochs=150, callbacks=[early_stopping], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "cea5abfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 1.2564 - accuracy: 0.5889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.256432056427002, 0.5888888835906982]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_model.evaluate(X_test_n, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "8cfe0d66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0924 - accuracy: 0.5000\n",
      "Epoch 2/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0880 - accuracy: 0.5037\n",
      "Epoch 3/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.0827 - accuracy: 0.5336\n",
      "Epoch 4/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0778 - accuracy: 0.5187\n",
      "Epoch 5/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0727 - accuracy: 0.5336\n",
      "Epoch 6/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.0681 - accuracy: 0.5485\n",
      "Epoch 7/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0630 - accuracy: 0.5560\n",
      "Epoch 8/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0578 - accuracy: 0.5485\n",
      "Epoch 9/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0534 - accuracy: 0.5485\n",
      "Epoch 10/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0481 - accuracy: 0.5485\n",
      "Epoch 11/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.0435 - accuracy: 0.5485\n",
      "Epoch 12/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0388 - accuracy: 0.5485\n",
      "Epoch 13/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0334 - accuracy: 0.5485\n",
      "Epoch 14/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.0279 - accuracy: 0.5485\n",
      "Epoch 15/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0217 - accuracy: 0.5522\n",
      "Epoch 16/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0159 - accuracy: 0.5522\n",
      "Epoch 17/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0096 - accuracy: 0.5522\n",
      "Epoch 18/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.0025 - accuracy: 0.5634\n",
      "Epoch 19/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.9955 - accuracy: 0.5672\n",
      "Epoch 20/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.9889 - accuracy: 0.5672\n",
      "Epoch 21/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.9818 - accuracy: 0.5858\n",
      "Epoch 22/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.9754 - accuracy: 0.5896\n",
      "Epoch 23/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.9686 - accuracy: 0.5896\n",
      "Epoch 24/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.9618 - accuracy: 0.5970\n",
      "Epoch 25/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.9558 - accuracy: 0.5970\n",
      "Epoch 26/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.9485 - accuracy: 0.5896\n",
      "Epoch 27/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.9422 - accuracy: 0.6007\n",
      "Epoch 28/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.9358 - accuracy: 0.6082\n",
      "Epoch 29/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.9302 - accuracy: 0.6082\n",
      "Epoch 30/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.9239 - accuracy: 0.6082\n",
      "Epoch 31/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.9181 - accuracy: 0.6082\n",
      "Epoch 32/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.9123 - accuracy: 0.6082\n",
      "Epoch 33/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.9076 - accuracy: 0.6045\n",
      "Epoch 34/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.9026 - accuracy: 0.6045\n",
      "Epoch 35/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8970 - accuracy: 0.6157\n",
      "Epoch 36/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8919 - accuracy: 0.6157\n",
      "Epoch 37/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.8872 - accuracy: 0.6157\n",
      "Epoch 38/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8835 - accuracy: 0.6157\n",
      "Epoch 39/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.8779 - accuracy: 0.6119\n",
      "Epoch 40/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8738 - accuracy: 0.6045\n",
      "Epoch 41/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8708 - accuracy: 0.6045\n",
      "Epoch 42/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8670 - accuracy: 0.6045\n",
      "Epoch 43/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8627 - accuracy: 0.6045\n",
      "Epoch 44/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8592 - accuracy: 0.6082\n",
      "Epoch 45/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8563 - accuracy: 0.6082\n",
      "Epoch 46/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8529 - accuracy: 0.6157\n",
      "Epoch 47/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8491 - accuracy: 0.6119\n",
      "Epoch 48/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8462 - accuracy: 0.6082\n",
      "Epoch 49/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.8441 - accuracy: 0.6157\n",
      "Epoch 50/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8407 - accuracy: 0.6194\n",
      "Epoch 51/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8362 - accuracy: 0.6157\n",
      "Epoch 52/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8354 - accuracy: 0.6231\n",
      "Epoch 53/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8301 - accuracy: 0.6269\n",
      "Epoch 54/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.8269 - accuracy: 0.6306\n",
      "Epoch 55/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8246 - accuracy: 0.6306\n",
      "Epoch 56/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8206 - accuracy: 0.6493\n",
      "Epoch 57/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8178 - accuracy: 0.6493\n",
      "Epoch 58/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8151 - accuracy: 0.6530\n",
      "Epoch 59/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8114 - accuracy: 0.6530\n",
      "Epoch 60/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8084 - accuracy: 0.6567\n",
      "Epoch 61/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8049 - accuracy: 0.6530\n",
      "Epoch 62/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8032 - accuracy: 0.6493\n",
      "Epoch 63/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.8009 - accuracy: 0.6493\n",
      "Epoch 64/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7985 - accuracy: 0.6567\n",
      "Epoch 65/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7953 - accuracy: 0.6567\n",
      "Epoch 66/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7927 - accuracy: 0.6604\n",
      "Epoch 67/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7913 - accuracy: 0.6604\n",
      "Epoch 68/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7884 - accuracy: 0.6642\n",
      "Epoch 69/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7864 - accuracy: 0.6604\n",
      "Epoch 70/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7841 - accuracy: 0.6642\n",
      "Epoch 71/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7811 - accuracy: 0.6642\n",
      "Epoch 72/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7786 - accuracy: 0.6642\n",
      "Epoch 73/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7763 - accuracy: 0.6642\n",
      "Epoch 74/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7741 - accuracy: 0.6604\n",
      "Epoch 75/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7723 - accuracy: 0.6642\n",
      "Epoch 76/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7696 - accuracy: 0.6716\n",
      "Epoch 77/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7680 - accuracy: 0.6716\n",
      "Epoch 78/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7678 - accuracy: 0.6716\n",
      "Epoch 79/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7640 - accuracy: 0.6679\n",
      "Epoch 80/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7628 - accuracy: 0.6642\n",
      "Epoch 81/150\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.7602 - accuracy: 0.6679\n",
      "Epoch 82/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7587 - accuracy: 0.6679\n",
      "Epoch 83/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7563 - accuracy: 0.6716\n",
      "Epoch 84/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7553 - accuracy: 0.6716\n",
      "Epoch 85/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7542 - accuracy: 0.6754\n",
      "Epoch 86/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7519 - accuracy: 0.6716\n",
      "Epoch 87/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7522 - accuracy: 0.6716\n",
      "Epoch 88/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7488 - accuracy: 0.6791\n",
      "Epoch 89/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7477 - accuracy: 0.6754\n",
      "Epoch 90/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7463 - accuracy: 0.6679\n",
      "Epoch 91/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7450 - accuracy: 0.6679\n",
      "Epoch 92/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7421 - accuracy: 0.6754\n",
      "Epoch 93/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7405 - accuracy: 0.6679\n",
      "Epoch 94/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7394 - accuracy: 0.6716\n",
      "Epoch 95/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7375 - accuracy: 0.6754\n",
      "Epoch 96/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7365 - accuracy: 0.6791\n",
      "Epoch 97/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7362 - accuracy: 0.6679\n",
      "Epoch 98/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7355 - accuracy: 0.6679\n",
      "Epoch 99/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7332 - accuracy: 0.6716\n",
      "Epoch 100/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7315 - accuracy: 0.6828\n",
      "Epoch 101/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7304 - accuracy: 0.6791\n",
      "Epoch 102/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7325 - accuracy: 0.6791\n",
      "Epoch 103/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7293 - accuracy: 0.6716\n",
      "Epoch 104/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7267 - accuracy: 0.6754\n",
      "Epoch 105/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7245 - accuracy: 0.6754\n",
      "Epoch 106/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7243 - accuracy: 0.6754\n",
      "Epoch 107/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7219 - accuracy: 0.6754\n",
      "Epoch 108/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7216 - accuracy: 0.6828\n",
      "Epoch 109/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7198 - accuracy: 0.6866\n",
      "Epoch 110/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7188 - accuracy: 0.6716\n",
      "Epoch 111/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7175 - accuracy: 0.6716\n",
      "Epoch 112/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7166 - accuracy: 0.6791\n",
      "Epoch 113/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7185 - accuracy: 0.6679\n",
      "Epoch 114/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7131 - accuracy: 0.6754\n",
      "Epoch 115/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7130 - accuracy: 0.6828\n",
      "Epoch 116/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7130 - accuracy: 0.6866\n",
      "Epoch 117/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7113 - accuracy: 0.6828\n",
      "Epoch 118/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7104 - accuracy: 0.6791\n",
      "Epoch 119/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7095 - accuracy: 0.6791\n",
      "Epoch 120/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7089 - accuracy: 0.6791\n",
      "Epoch 121/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7072 - accuracy: 0.6828\n",
      "Epoch 122/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.7059 - accuracy: 0.6791\n",
      "Epoch 123/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7045 - accuracy: 0.6791\n",
      "Epoch 124/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7039 - accuracy: 0.6866\n",
      "Epoch 125/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7024 - accuracy: 0.6791\n",
      "Epoch 126/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7017 - accuracy: 0.6866\n",
      "Epoch 127/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7035 - accuracy: 0.6791\n",
      "Epoch 128/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6996 - accuracy: 0.6828\n",
      "Epoch 129/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6990 - accuracy: 0.6828\n",
      "Epoch 130/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.6866\n",
      "Epoch 131/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6966 - accuracy: 0.6828\n",
      "Epoch 132/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.6791\n",
      "Epoch 133/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.6791\n",
      "Epoch 134/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6940 - accuracy: 0.6828\n",
      "Epoch 135/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.6828\n",
      "Epoch 136/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6919 - accuracy: 0.6828\n",
      "Epoch 137/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6906 - accuracy: 0.6828\n",
      "Epoch 138/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6899 - accuracy: 0.6866\n",
      "Epoch 139/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6905 - accuracy: 0.6866\n",
      "Epoch 140/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6878 - accuracy: 0.6866\n",
      "Epoch 141/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6870 - accuracy: 0.6828\n",
      "Epoch 142/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6868 - accuracy: 0.6828\n",
      "Epoch 143/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6843 - accuracy: 0.6828\n",
      "Epoch 144/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6847 - accuracy: 0.6791\n",
      "Epoch 145/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6842 - accuracy: 0.6791\n",
      "Epoch 146/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6831 - accuracy: 0.6791\n",
      "Epoch 147/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.6791\n",
      "Epoch 148/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6804 - accuracy: 0.6791\n",
      "Epoch 149/150\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.6828\n",
      "Epoch 150/150\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.6828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f9fed6a108>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(7, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(7, activation = tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(3, activation = tf.nn.softmax))\n",
    "es = EarlyStopping(monitor='accuracy', mode='min', verbose=1)\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "model.fit(x = X_train_n, y= y_train,  epochs = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "c7958b43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8641 - accuracy: 0.5889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8641465902328491, 0.5888888835906982]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_n, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c88e8f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step\n",
      "number of bets made: 90\n",
      "\n",
      "profit on $100 bankroll: $8.923\n",
      "\n",
      "draw_profits    -89.5305\n",
      "home_profits    100.8850\n",
      "away_profits     -2.4312\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "preds = pd.DataFrame(h_model.predict(X_test_n), columns = ['pred 0','pred 1','pred 2'])\n",
    "predicted_df = pd.concat([X_test.reset_index(drop = True), preds], axis = 1)\n",
    "# bo_po_dha = list(zip(predicted_df[['med_0','med_1','med_2']],predicted_df[['pred 0','pred 1','pred 2']],['draw','home','away']))\n",
    "bo_po_dha = list(zip(predicted_df[['75_0','75_1','75_2']],predicted_df[['pred 0','pred 1','pred 2']],['draw','home','away']))\n",
    "for book_odds, pred_odds, dha in bo_po_dha:\n",
    "    predicted_df[dha] = predicted_df.apply(lambda x: kelly(x[pred_odds], x[book_odds], 0.25), axis=1)\n",
    "predicted_df['target'] = y_test.reset_index(drop=True)\n",
    "dha = {'draw':'0','home':'1','away':'2'}\n",
    "predicted_df = predicted_df.replace('no value', 0)\n",
    "predicted_df[['draw','home','away']] = predicted_df[['draw','home','away']].astype(float)\n",
    "for word, number in dha.items():\n",
    "    predicted_df[f'{word}_profits'] = np.where(predicted_df['target'] == int(number),\n",
    "                                    predicted_df[word] * (predicted_df['75_'+ number] - 1) * 100,\n",
    "                                    -100*predicted_df[word])\n",
    "\n",
    "predicted_df['profits'] = predicted_df[predicted_df.columns[-3:]].sum(axis = 1)\n",
    "p = round(np.sum(predicted_df[\"profits\"]),3)\n",
    "predicted_df = predicted_df.round(4)\n",
    "print(f'number of bets made: {predicted_df.shape[0]}\\n')\n",
    "print(f'profit on $100 bankroll: ${p}\\n')\n",
    "print(predicted_df.sum()[-4:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "464f76ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "checker = predicted_df[['score_diff','med_0','med_1','med_2','odds_sum','pred 0','pred 1',\n",
    "              'pred 2','target','draw','home','away','draw_profits','home_profits','away_profits','profits']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ba12b2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\idotz\\anaconda3\\envs\\p37\\lib\\site-packages\\pandas\\core\\frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "odds_compare = checker[['med_0','med_1','med_2']]\n",
    "odds_compare[['predo_0','predo_1','predo_2']] = checker[['pred 0','pred 1','pred 2']].apply(lambda x: 1/x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9a2a1d95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>med_0</th>\n",
       "      <th>med_1</th>\n",
       "      <th>med_2</th>\n",
       "      <th>predo_0</th>\n",
       "      <th>predo_1</th>\n",
       "      <th>predo_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.5000</td>\n",
       "      <td>1.2000</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>7.057163</td>\n",
       "      <td>1.237164</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.5000</td>\n",
       "      <td>11.0000</td>\n",
       "      <td>1.4444</td>\n",
       "      <td>4.048583</td>\n",
       "      <td>17.301039</td>\n",
       "      <td>1.438228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0000</td>\n",
       "      <td>1.1333</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>8.952552</td>\n",
       "      <td>1.169180</td>\n",
       "      <td>30.395136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.8500</td>\n",
       "      <td>1.4000</td>\n",
       "      <td>8.5000</td>\n",
       "      <td>5.385030</td>\n",
       "      <td>1.372684</td>\n",
       "      <td>11.655012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.0000</td>\n",
       "      <td>1.0250</td>\n",
       "      <td>51.0000</td>\n",
       "      <td>11.750881</td>\n",
       "      <td>1.117693</td>\n",
       "      <td>49.504951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.4500</td>\n",
       "      <td>2.6000</td>\n",
       "      <td>3.6000</td>\n",
       "      <td>3.266906</td>\n",
       "      <td>4.859087</td>\n",
       "      <td>2.048760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.9000</td>\n",
       "      <td>1.4444</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>5.005005</td>\n",
       "      <td>1.434309</td>\n",
       "      <td>9.708738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.7000</td>\n",
       "      <td>2.9000</td>\n",
       "      <td>2.7500</td>\n",
       "      <td>3.325573</td>\n",
       "      <td>3.205128</td>\n",
       "      <td>2.582645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.2250</td>\n",
       "      <td>1.3417</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>5.608525</td>\n",
       "      <td>1.350986</td>\n",
       "      <td>12.269938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.2500</td>\n",
       "      <td>1.5714</td>\n",
       "      <td>7.5000</td>\n",
       "      <td>44.642860</td>\n",
       "      <td>1.024905</td>\n",
       "      <td>526.315796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.7250</td>\n",
       "      <td>1.8333</td>\n",
       "      <td>6.1250</td>\n",
       "      <td>3.492840</td>\n",
       "      <td>2.110150</td>\n",
       "      <td>4.170142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.5000</td>\n",
       "      <td>1.3000</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>7.552870</td>\n",
       "      <td>1.217285</td>\n",
       "      <td>21.645021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.6000</td>\n",
       "      <td>11.0000</td>\n",
       "      <td>1.3000</td>\n",
       "      <td>4.142502</td>\n",
       "      <td>19.569471</td>\n",
       "      <td>1.413428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.3750</td>\n",
       "      <td>3.4000</td>\n",
       "      <td>2.6250</td>\n",
       "      <td>3.346720</td>\n",
       "      <td>5.787037</td>\n",
       "      <td>1.892864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.4500</td>\n",
       "      <td>1.3158</td>\n",
       "      <td>11.0000</td>\n",
       "      <td>5.144033</td>\n",
       "      <td>1.412429</td>\n",
       "      <td>10.245902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.9474</td>\n",
       "      <td>2.3500</td>\n",
       "      <td>3.2000</td>\n",
       "      <td>3.265839</td>\n",
       "      <td>2.757860</td>\n",
       "      <td>3.019324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.7000</td>\n",
       "      <td>6.5000</td>\n",
       "      <td>1.5333</td>\n",
       "      <td>4.416961</td>\n",
       "      <td>31.948881</td>\n",
       "      <td>1.347164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.6250</td>\n",
       "      <td>2.5500</td>\n",
       "      <td>3.2500</td>\n",
       "      <td>3.259452</td>\n",
       "      <td>3.026634</td>\n",
       "      <td>2.756340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.0000</td>\n",
       "      <td>1.1333</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>11.750881</td>\n",
       "      <td>1.118193</td>\n",
       "      <td>48.543690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.3333</td>\n",
       "      <td>1.3636</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>5.515720</td>\n",
       "      <td>1.363141</td>\n",
       "      <td>11.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.3750</td>\n",
       "      <td>2.5500</td>\n",
       "      <td>3.8000</td>\n",
       "      <td>3.483107</td>\n",
       "      <td>1.869159</td>\n",
       "      <td>5.621135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.4500</td>\n",
       "      <td>2.7000</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>3.280840</td>\n",
       "      <td>2.632965</td>\n",
       "      <td>3.171583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.0000</td>\n",
       "      <td>1.1818</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>13.192612</td>\n",
       "      <td>1.102901</td>\n",
       "      <td>57.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.3000</td>\n",
       "      <td>2.6000</td>\n",
       "      <td>3.8000</td>\n",
       "      <td>3.304693</td>\n",
       "      <td>4.156276</td>\n",
       "      <td>2.189142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.1269</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>1.8167</td>\n",
       "      <td>3.149606</td>\n",
       "      <td>4.683841</td>\n",
       "      <td>2.131742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.5500</td>\n",
       "      <td>2.6000</td>\n",
       "      <td>3.2750</td>\n",
       "      <td>3.260515</td>\n",
       "      <td>3.478261</td>\n",
       "      <td>2.464268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.0000</td>\n",
       "      <td>1.0125</td>\n",
       "      <td>67.0000</td>\n",
       "      <td>18.903591</td>\n",
       "      <td>1.065757</td>\n",
       "      <td>113.636368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.5500</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>5.2500</td>\n",
       "      <td>6.049607</td>\n",
       "      <td>1.301744</td>\n",
       "      <td>15.037594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3.3000</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>1.6154</td>\n",
       "      <td>4.264392</td>\n",
       "      <td>23.201857</td>\n",
       "      <td>1.384275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.6000</td>\n",
       "      <td>2.3000</td>\n",
       "      <td>3.8000</td>\n",
       "      <td>3.332223</td>\n",
       "      <td>2.701972</td>\n",
       "      <td>3.032140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6.0000</td>\n",
       "      <td>1.1818</td>\n",
       "      <td>19.0000</td>\n",
       "      <td>7.022472</td>\n",
       "      <td>1.242236</td>\n",
       "      <td>19.011406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.8000</td>\n",
       "      <td>15.0000</td>\n",
       "      <td>1.2500</td>\n",
       "      <td>5.885815</td>\n",
       "      <td>84.745758</td>\n",
       "      <td>1.222046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3.4000</td>\n",
       "      <td>1.4444</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>5.279831</td>\n",
       "      <td>1.389082</td>\n",
       "      <td>11.025358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3.5000</td>\n",
       "      <td>1.4000</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>12.562815</td>\n",
       "      <td>1.108893</td>\n",
       "      <td>53.475937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2.4500</td>\n",
       "      <td>5.7000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>3.010235</td>\n",
       "      <td>4.399472</td>\n",
       "      <td>2.270148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4.6000</td>\n",
       "      <td>12.5000</td>\n",
       "      <td>1.2857</td>\n",
       "      <td>4.442470</td>\n",
       "      <td>29.411762</td>\n",
       "      <td>1.349710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2.4000</td>\n",
       "      <td>2.7500</td>\n",
       "      <td>3.2250</td>\n",
       "      <td>3.284072</td>\n",
       "      <td>2.683843</td>\n",
       "      <td>3.096934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2.6000</td>\n",
       "      <td>4.2000</td>\n",
       "      <td>2.2000</td>\n",
       "      <td>3.498950</td>\n",
       "      <td>8.025682</td>\n",
       "      <td>1.696353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2.4773</td>\n",
       "      <td>2.7000</td>\n",
       "      <td>3.2000</td>\n",
       "      <td>3.837299</td>\n",
       "      <td>1.747946</td>\n",
       "      <td>5.977286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.9000</td>\n",
       "      <td>1.6500</td>\n",
       "      <td>7.5000</td>\n",
       "      <td>5.810575</td>\n",
       "      <td>1.321178</td>\n",
       "      <td>14.084507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      med_0    med_1    med_2    predo_0    predo_1     predo_2\n",
       "0    5.5000   1.2000  13.0000   7.057163   1.237164   20.000000\n",
       "1    3.5000  11.0000   1.4444   4.048583  17.301039    1.438228\n",
       "2    7.0000   1.1333  25.0000   8.952552   1.169180   30.395136\n",
       "3    3.8500   1.4000   8.5000   5.385030   1.372684   11.655012\n",
       "4   19.0000   1.0250  51.0000  11.750881   1.117693   49.504951\n",
       "5    2.4500   2.6000   3.6000   3.266906   4.859087    2.048760\n",
       "6    3.9000   1.4444   8.0000   5.005005   1.434309    9.708738\n",
       "7    2.7000   2.9000   2.7500   3.325573   3.205128    2.582645\n",
       "8    4.2250   1.3417   9.0000   5.608525   1.350986   12.269938\n",
       "9    3.2500   1.5714   7.5000  44.642860   1.024905  526.315796\n",
       "10   2.7250   1.8333   6.1250   3.492840   2.110150    4.170142\n",
       "11   4.5000   1.3000  13.0000   7.552870   1.217285   21.645021\n",
       "12   4.6000  11.0000   1.3000   4.142502  19.569471    1.413428\n",
       "13   2.3750   3.4000   2.6250   3.346720   5.787037    1.892864\n",
       "14   4.4500   1.3158  11.0000   5.144033   1.412429   10.245902\n",
       "15   2.9474   2.3500   3.2000   3.265839   2.757860    3.019324\n",
       "16   3.7000   6.5000   1.5333   4.416961  31.948881    1.347164\n",
       "17   2.6250   2.5500   3.2500   3.259452   3.026634    2.756340\n",
       "18   7.0000   1.1333  23.0000  11.750881   1.118193   48.543690\n",
       "19   4.3333   1.3636   9.5000   5.515720   1.363141   11.764706\n",
       "20   2.3750   2.5500   3.8000   3.483107   1.869159    5.621135\n",
       "21   2.4500   2.7000   3.5000   3.280840   2.632965    3.171583\n",
       "22   6.0000   1.1818  18.0000  13.192612   1.102901   57.142857\n",
       "23   2.3000   2.6000   3.8000   3.304693   4.156276    2.189142\n",
       "24   3.1269   4.5000   1.8167   3.149606   4.683841    2.131742\n",
       "25   2.5500   2.6000   3.2750   3.260515   3.478261    2.464268\n",
       "26  26.0000   1.0125  67.0000  18.903591   1.065757  113.636368\n",
       "27   2.5500   2.0000   5.2500   6.049607   1.301744   15.037594\n",
       "28   3.3000   6.0000   1.6154   4.264392  23.201857    1.384275\n",
       "29   2.6000   2.3000   3.8000   3.332223   2.701972    3.032140\n",
       "30   6.0000   1.1818  19.0000   7.022472   1.242236   19.011406\n",
       "31   4.8000  15.0000   1.2500   5.885815  84.745758    1.222046\n",
       "32   3.4000   1.4444  10.5000   5.279831   1.389082   11.025358\n",
       "33   3.5000   1.4000  13.0000  12.562815   1.108893   53.475937\n",
       "34   2.4500   5.7000   2.0000   3.010235   4.399472    2.270148\n",
       "35   4.6000  12.5000   1.2857   4.442470  29.411762    1.349710\n",
       "36   2.4000   2.7500   3.2250   3.284072   2.683843    3.096934\n",
       "37   2.6000   4.2000   2.2000   3.498950   8.025682    1.696353\n",
       "38   2.4773   2.7000   3.2000   3.837299   1.747946    5.977286\n",
       "39   2.9000   1.6500   7.5000   5.810575   1.321178   14.084507"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odds_compare.head(40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
